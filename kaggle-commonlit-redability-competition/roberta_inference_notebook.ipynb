{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roberta-inference-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsNGt4Cbo+oF4ihgNcFpvR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd0MA3JgBpsA",
        "outputId": "d8e7e8a2-8da3-4d42-ffc8-547ef0ae25b5"
      },
      "source": [
        "# Kaggle instalaltion in Colab # https://www.kaggle.com/general/74235\n",
        "!pip install kaggle\n",
        "!pip install transformers\n",
        "!pip install colorama"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojB6e0yTBxx4",
        "outputId": "3c8d5a73-fc07-4ad4-c969-c8174247dd16"
      },
      "source": [
        "# Here I'll use the kaggle dataset from Commolit Readability Competition https://www.kaggle.com/c/commonlitreadabilityprize/data\n",
        "# At first let me Mount my drive to get the dataset\n",
        "HOME_PATH = \"/content\"\n",
        "%cd \"$HOME_PATH\"\n",
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")\n",
        "# Kaggle dataset path\n",
        "KAGGLE_PATH = \"/content/drive/My Drive/Data Science/data/\"\n",
        "DATASET_PATH = \"/content/drive/My Drive/Data Science/data/commonlitreadabilityprize/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHMFNuaXCgU1"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp \"/content/drive/My Drive/Data Science/data/kaggle.json\" ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2KBTkAWC9Wo",
        "outputId": "facf3cb8-fb02-4737-b2b1-fee377af0e44"
      },
      "source": [
        "!kaggle competitions download -c commonlitreadabilityprize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/108 [00:00<?, ?B/s]\n",
            "100% 108/108 [00:00<00:00, 246kB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/6.79k [00:00<?, ?B/s]\n",
            "100% 6.79k/6.79k [00:00<00:00, 6.81MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/1.13M [00:00<?, ?B/s]\n",
            "100% 1.13M/1.13M [00:00<00:00, 37.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TMMP0LbDWc8",
        "outputId": "05043639-37ee-41f0-9488-b7049ff8f955"
      },
      "source": [
        "!mkdir input\n",
        "!unzip train.csv.zip -d input\n",
        "#!unzip file.zip -d input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: input/train.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAfZlD5uBYoK"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import cv2\n",
        "import math\n",
        "import time\n",
        "import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader,Sampler\n",
        "\n",
        "from transformers import (AutoModel, AutoTokenizer,\n",
        "                          AutoConfig ,AutoModelForSequenceClassification)\n",
        "\n",
        "from colorama import Fore, Back, Style\n",
        "y_ = Fore.YELLOW\n",
        "r_ = Fore.RED\n",
        "g_ = Fore.GREEN\n",
        "b_ = Fore.BLUE\n",
        "m_ = Fore.MAGENTA\n",
        "c_ = Fore.CYAN\n",
        "sr_ = Style.RESET_ALL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSaJiQ-cEWGH"
      },
      "source": [
        "train_data = pd.read_csv('input/train.csv')\n",
        "test_data = pd.read_csv('input/test.csv')\n",
        "#sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxlGDyUrEXEk"
      },
      "source": [
        "config = {\n",
        "    'learning_rate':2e-5,\n",
        "    'batch_size':16,\n",
        "    'epochs':3,\n",
        "    'nfolds':5,\n",
        "    'seed':42,\n",
        "    'max_len':256,\n",
        "}\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=config['seed'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z054vMFGEZ92"
      },
      "source": [
        "class CLRPDataset(Dataset):\n",
        "    def __init__(self,df,tokenizer):\n",
        "        self.excerpt = df['excerpt'].to_numpy()\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n",
        "                                max_length=config['max_len'],\n",
        "                                padding='max_length',truncation=True)\n",
        "        return encode\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.excerpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX68SZpqEcNo"
      },
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.middle_features = hidden_dim\n",
        "\n",
        "        self.W = nn.Linear(in_features, hidden_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1)\n",
        "        self.out_features = hidden_dim\n",
        "\n",
        "    def forward(self, features):\n",
        "        att = torch.tanh(self.W(features))\n",
        "\n",
        "        score = self.V(att)\n",
        "\n",
        "        attention_weights = torch.softmax(score, dim=1)\n",
        "\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "\n",
        "        return context_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKG-hntCEekd"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,model_path):\n",
        "        super(Model,self).__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(model_path) \n",
        "        self.config = AutoConfig.from_pretrained(model_path)\n",
        "        self.head = AttentionHead(self.config.hidden_size,self.config.hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(self.config.hidden_size,1)\n",
        "\n",
        "    def forward(self,**xb):\n",
        "        x = self.roberta(**xb)[0]\n",
        "        x = self.head(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHFhTE6mEioP"
      },
      "source": [
        "def get_prediction(df,path,model_path,device='cuda'):        \n",
        "    model = Model(model_path)\n",
        "    model.load_state_dict(torch.load(path,map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    \n",
        "    test_ds = CLRPDataset(df,tokenizer)\n",
        "    test_dl = DataLoader(test_ds,\n",
        "                        batch_size = config[\"batch_size\"],\n",
        "                        shuffle=False,\n",
        "                        num_workers = 4,\n",
        "                        pin_memory=True)\n",
        "    \n",
        "    predictions = list()\n",
        "    for i, (inputs) in tqdm(enumerate(test_dl)):\n",
        "        inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
        "        outputs = model(**inputs)\n",
        "        outputs = outputs.cpu().detach().numpy().ravel().tolist()\n",
        "        predictions.extend(outputs)\n",
        "        \n",
        "    torch.cuda.empty_cache()\n",
        "    return np.array(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIClWaDREk9Q"
      },
      "source": [
        "pred1 = get_prediction(test_data,f'{DATASET_PATH}/clr-roberta/model0/model0.bin',f'{DATASET_PATH}/clrp_roberta_base')\n",
        "pred2 = get_prediction(test_data,'../input/clr-roberta/model1/model1.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "pred3 = get_prediction(test_data,'../input/clr-roberta/model2/model2.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "pred4 = get_prediction(test_data,'../input/clr-roberta/model3/model3.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "pred5 = get_prediction(test_data,'../input/clr-roberta/model4/model4.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "\n",
        "predictions1 = (pred1 + pred2 + pred3 + pred4 + pred5)/5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urUAxzA-E4rp"
      },
      "source": [
        "pred1 = get_prediction(test_data,'../input/clrp-roberta-base-models-tpu/model0/model0.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "pred2 = get_prediction(test_data,'../input/clrp-roberta-base-models-tpu/model1/model1.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "pred3 = get_prediction(test_data,'../input/clrp-roberta-base-models-tpu/model2/model2.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "pred4 = get_prediction(test_data,'../input/clrp-roberta-base-models-tpu/model3/model3.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "pred5 = get_prediction(test_data,'../input/clrp-roberta-base-models-tpu/model4/model4.bin','../input/clrp-roberta-base/clrp_roberta_base')\n",
        "predictions2 = (pred1 + pred2 + pred3 + pred4 + pred5)/5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0LH4zaeE5Xl"
      },
      "source": [
        "sample['target'] = (predictions1 + predictions2)/2\n",
        "sample.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iv9IdBUE-mp"
      },
      "source": [
        "sample"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}