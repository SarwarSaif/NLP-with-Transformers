{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "financial-text-sentiment-analysis-using-pretrained-finbert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+tz3WrJJH/9KydpjKA2Ix"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOgs-vvf8fFe"
      },
      "source": [
        "# Install Transformer from HuggingFace\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89-x3O_ePpGH"
      },
      "source": [
        "Steps:\n",
        "\n",
        "1. Tokenize\n",
        "2. Token IDs -> model\n",
        "3. Model activations -> Probabilities (using Softmax)\n",
        "4. Argmax of Probabilities "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av-eTuPk4pHf"
      },
      "source": [
        "model_name = 'ProsusAI/finbert'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zukdgKP071IJ"
      },
      "source": [
        "# Sequence Classification model\n",
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaDlralq8PP9"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihHvPZw2O3fO"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "43gk3ZvQPY4s",
        "outputId": "9a07dc77-e29b-45c6-9518-8ace6aee56e2"
      },
      "source": [
        "# a news from an Yahoo Finance\n",
        "text = ('Rebecca Rubin Mon, July 12, 2021, 1:14 AM DIS \\+2.45\\% By Rebecca Rubin LOS ANGELES, July 11, (Variety.com) - Disney and Marvel\\'s superhero adventure \"Black Widow\" \\\\\n",
        "captured a massive $80 million in its first weekend, crushing the benchmark for the biggest opening weekend since the pandemic. \\\\\n",
        "In a first for the Marvel Cinematic Universe, the film opened simultaneously in theaters and on Disney Plus as part of the streaming service\\'s Premier Access offering, \\\\\n",
        "where subscribers can rent \"Black Widow\" for an extra $30. Disney reported that \"Black Widow\" generated more than $60 million \"in Disney Plus Premier Access consumer spend \\\\\n",
        "globally,\" marking the rare occasion in which a studio discloses revenues for digital rentals. Overseas, \"Black Widow\" collected $78 million in its debut, boosting its global box office \\\\\n",
        "haul to $158 million. Disney didn\\'t share viewership data for the previously released \"Cruella\" starring Emma Stone and the animated \"Raya and the Last Dragon,\" \\\\\n",
        "which also premiered simultaneously in theaters and on Disney Plus. It\\'s unclear if Disney will continue to report digital rentals for the upcoming action adventure \"Jungle Cruise,\" \\\\\n",
        "which opens in cinemas and on Disney Plus on July 30. In a statement on Sunday morning, Disney\\'s media and entertainment distribution chairman Kareem Daniel said \\\\\n",
        "\"\\'Black Widow\\'s\\' strong performance this weekend affirms our flexible distribution strategy of making franchise films available in theaters for a true cinematic experience and, \\\\\n",
        "as COVID concerns continue globally, providing choice to consumers who prefer to watch at home on Disney Plus.\"')\n",
        "\n",
        "text\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Rebecca Rubin Mon, July 12, 2021, 1:14 AM DIS \\\\+2.45\\\\% By Rebecca Rubin LOS ANGELES, July 11, (Variety.com) - Disney and Marvel\\'s superhero adventure \"Black Widow\" \\\\captured a massive $80 million in its first weekend, crushing the benchmark for the biggest opening weekend since the pandemic. \\\\In a first for the Marvel Cinematic Universe, the film opened simultaneously in theaters and on Disney Plus as part of the streaming service\\'s Premier Access offering, \\\\where subscribers can rent \"Black Widow\" for an extra $30. Disney reported that \"Black Widow\" generated more than $60 million \"in Disney Plus Premier Access consumer spend \\\\globally,\" marking the rare occasion in which a studio discloses revenues for digital rentals. Overseas, \"Black Widow\" collected $78 million in its debut, boosting its global box office \\\\haul to $158 million. Disney didn\\'t share viewership data for the previously released \"Cruella\" starring Emma Stone and the animated \"Raya and the Last Dragon,\" \\\\which also premiered simultaneously in theaters and on Disney Plus. It\\'s unclear if Disney will continue to report digital rentals for the upcoming action adventure \"Jungle Cruise,\" \\\\which opens in cinemas and on Disney Plus on July 30. In a statement on Sunday morning, Disney\\'s media and entertainment distribution chairman Kareem Daniel said \"\\'Black Widow\\'s\\' strong performance this weekend affirms our flexible distribution strategy of making franchise films available in theaters for a true cinematic experience and, \\x07s COVID concerns continue globally, providing choice to consumers who prefer to watch at home on Disney Plus.\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvlw2yE7QboL"
      },
      "source": [
        "tokens = tokenizer.encode_plus(text, \n",
        "                               max_length=512, # Maximum token size\n",
        "                               truncation=True, # If tokens lenght > max_length: Truncate excess part\n",
        "                               padding='max_length', # If tokens length < max_length: Pad token until == max_length\n",
        "                               add_special_tokens=True,\n",
        "                               return_tensors='pt', # Tensors: pytorch-> 'pt', tensorflow-> 'tf' or numpy tensors\n",
        "                               )  \n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adGhr2JCUx2o"
      },
      "source": [
        "### BERT Special Toke IDs\n",
        "[CLS] = 101\n",
        "\n",
        "[SEP] = 102\n",
        "\n",
        "[MASK] = 103\n",
        "\n",
        "[UNK] = 100\n",
        "\n",
        "[PAD] = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5padP5DxUcvW",
        "outputId": "74272bd4-7c25-4d07-8fe1-ce1c1cfdbd9c"
      },
      "source": [
        "tokens"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  9423, 20524, 12256,  1010,  2251,  2260,  1010, 25682,  1010,\n",
              "          1015,  1024,  2403,  2572,  4487,  2015,  1032,  1009,  1016,  1012,\n",
              "          3429,  1032,  1003,  2011,  9423, 20524,  3050,  3349,  1010,  2251,\n",
              "          2340,  1010,  1006,  3528,  1012,  4012,  1007,  1011,  6373,  1998,\n",
              "          8348,  1005,  1055, 16251,  6172,  1000,  2304,  7794,  1000,  1032,\n",
              "          4110,  1037,  5294,  1002,  3770,  2454,  1999,  2049,  2034,  5353,\n",
              "          1010, 14527,  1996,  6847, 10665,  2005,  1996,  5221,  3098,  5353,\n",
              "          2144,  1996,  6090,  3207,  7712,  1012,  1032,  1999,  1037,  2034,\n",
              "          2005,  1996,  8348, 21014,  5304,  1010,  1996,  2143,  2441,  7453,\n",
              "          1999, 12370,  1998,  2006,  6373,  4606,  2004,  2112,  1997,  1996,\n",
              "         11058,  2326,  1005,  1055,  4239,  3229,  5378,  1010,  1032,  2073,\n",
              "         17073,  2064,  9278,  1000,  2304,  7794,  1000,  2005,  2019,  4469,\n",
              "          1002,  2382,  1012,  6373,  2988,  2008,  1000,  2304,  7794,  1000,\n",
              "          7013,  2062,  2084,  1002,  3438,  2454,  1000,  1999,  6373,  4606,\n",
              "          4239,  3229,  7325,  5247,  1032, 16452,  1010,  1000, 10060,  1996,\n",
              "          4678,  6686,  1999,  2029,  1037,  2996, 26056,  2015, 12594,  2005,\n",
              "          3617, 12635,  2015,  1012,  6931,  1010,  1000,  2304,  7794,  1000,\n",
              "          5067,  1002,  6275,  2454,  1999,  2049,  2834,  1010, 12992,  2075,\n",
              "          2049,  3795,  3482,  2436,  1032, 14655,  2000,  1002, 17696,  2454,\n",
              "          1012,  6373,  2134,  1005,  1056,  3745,  7193,  5605,  2951,  2005,\n",
              "          1996,  3130,  2207,  1000, 10311,  2721,  1000,  4626,  5616,  2962,\n",
              "          1998,  1996,  6579,  1000,  4097,  2050,  1998,  1996,  2197,  5202,\n",
              "          1010,  1000,  1032,  2029,  2036,  5885,  7453,  1999, 12370,  1998,\n",
              "          2006,  6373,  4606,  1012,  2009,  1005,  1055, 10599,  2065,  6373,\n",
              "          2097,  3613,  2000,  3189,  3617, 12635,  2015,  2005,  1996,  9046,\n",
              "          2895,  6172,  1000,  8894,  8592,  1010,  1000,  1032,  2029,  7480,\n",
              "          1999, 19039,  1998,  2006,  6373,  4606,  2006,  2251,  2382,  1012,\n",
              "          1999,  1037,  4861,  2006,  4465,  2851,  1010,  6373,  1005,  1055,\n",
              "          2865,  1998,  4024,  4353,  3472, 10556,  9910,  2213,  3817,  2056,\n",
              "          1000,  1005,  2304,  7794,  1005,  1055,  1005,  2844,  2836,  2023,\n",
              "          5353, 21358, 27972,  2015,  2256, 12379,  4353,  5656,  1997,  2437,\n",
              "          6329,  3152,  2800,  1999, 12370,  2005,  1037,  2995, 21014,  3325,\n",
              "          1998,  1010,  1055,  2522, 17258,  5936,  3613, 16452,  1010,  4346,\n",
              "          3601,  2000, 10390,  2040,  9544,  2000,  3422,  2012,  2188,  2006,\n",
              "          6373,  4606,  1012,  1000,   102,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdYlFKppWQU0"
      },
      "source": [
        "#### without **kwargs\n",
        "random_func(var1='hello', var2='world')\n",
        "\n",
        "#### with **kwargs\n",
        "input_dict = {var1='hello', var2='world'}\n",
        "\n",
        "random_func(**input_dict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBR9a7RmVGkx"
      },
      "source": [
        "output = model(**tokens)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hclNkH9W8p1",
        "outputId": "4b0c44a7-fade-4c30-a08c-9f12022c6c84"
      },
      "source": [
        "output"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('logits',\n",
              "                           tensor([[ 1.9429, -2.3052, -0.6809]], grad_fn=<AddmmBackward>))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG5YZ-0tW--i",
        "outputId": "b6fb7596-f63b-4f12-f0c9-66ff84c8da94"
      },
      "source": [
        "output[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9429, -2.3052, -0.6809]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYBnkcXaXEuP",
        "outputId": "c439ad90-7537-4839-8026-286b7456a052"
      },
      "source": [
        "# Convert Output Activations into Probabilities\n",
        "import torch.nn.functional as F\n",
        "probs = F.softmax(output[0], dim=-1) # -1 means final dimension. If we don't specify the dimensions it'll give error\n",
        "probs"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9201, 0.0132, 0.0667]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GJxkiNCXWGn"
      },
      "source": [
        "import torch\n",
        "# Get the maximum predicted class\n",
        "pred = torch.argmax(probs)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrHqBfw5YBxh",
        "outputId": "d814ac2b-4481-40cf-c727-1e52ac199a88"
      },
      "source": [
        "pred.item()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K78jq_3aYD7V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}